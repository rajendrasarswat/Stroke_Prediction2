pip install joblib
import joblib
import numpy as np
import pandas as pd
import time as timer
import seaborn as sns
import streamlit as st

from sklearn import metrics
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.metrics import classification_report,accuracy_score,confusion_matrix
from sklearn.metrics import auc,roc_auc_score,roc_curve,precision_score,recall_score,f1_score


#model imports
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from xgboost import plot_importance

#charts
import plotly.express as px
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots


st.markdown(
        f"""
        <style>
            .block-container{{
                min-width: 65vw;
            }}
            #MainMenu {{visibility: hidden;}}
            footer {{visibility: hidden;}}
            footer:after {{
                content:' Made with â™¥ by AIML Team 11 of Virtusa Codelite Hackathon 2021'; 
                visibility: visible;
                display: flex;
                justify-content: center;
                color: white;
                background-color: #f63366;
                padding: -5px;
            }}
        </style>
        """,
        unsafe_allow_html=True,
    )

def main():
    st.title("STROKE PREDICTION AND ANALYSIS USING MACHINE LEARNING")

    st.header("AIML TEAM 11")

    st.subheader("Virtusa Codelite Hackathon 2021")

    menu = ["Prediction","Model Details"]
    activity = st.selectbox("Select a Menu",menu)

    if activity == "Model Details":

        st.subheader("Cleaned Dataset")
        #loading dataframe
        df = pd.read_csv("train.csv")

        #Filling Missing values of bmi using mean
        df['bmi'] = df['bmi'].fillna(df.groupby('age')['bmi'].transform('mean'))
        df.fillna(df[['bmi']].mean(),inplace=True)
        
        #Dropping ID attribute
        df.drop(['id'],axis=1,inplace=True)
        st.dataframe(df)
        
        st.subheader("Data Visualizations")

        #Heart disease vs stroke histogram
        fig = px.histogram(df, x = df['heart_disease'], y = df['stroke'],labels={
            'heart_disease':"Heart Disease",
            'stroke':"Number of Strokes",
        }, title='Heart Disease Vs Stroke')
        st.write(fig)

        #histogram buttons
        col1, col2, col3 = st.beta_columns(3)
        col4, col5, col6 = st.beta_columns(3)

        #Age vs stroke histogram
        if col1.button("Age Vs Occurance of Stroke"):
            fig = px.histogram(df, x = df['age'], y = df['stroke'],labels={
                "age":"Age",
            }, title='Age Vs Occurance of Stroke')
            st.write(fig)

        #Smoking Status vs stroke histogram
        if col2.button("Smoking Status Vs Occurance of Stroke"):
            fig = px.histogram(df, x = df['smoking_status'], y = df['stroke'],labels={
                "smoking_status":"Smoking Status",
            }, title='Smoking Status Vs Occurance of Stroke')
            st.write(fig)

        #Hypertension vs stroke histogram
        if col3.button("Hypertension Vs Occurance of Stroke"):
            fig = px.histogram(df, x = df['hypertension'], y = df['stroke'],labels={
                "hypertension":"Hypertension",
            }, title='Hypertension Vs Occurance of Stroke')
            st.write(fig)

        #BMI vs stroke histogram      
        if col4.button("BMI vs Occurance of Stoke"):
            fig = px.histogram(df, x = df['bmi'], y = df['stroke'],labels={
                "bmi":"BMI",
            }, title='BMI Vs Occurance of Stroke')
            st.write(fig)

        #Average Glucose level vs stroke histogram
        if col5.button("Average Glucose Level vs Occurance of Stoke"):
            fig = px.histogram(df, x = df['avg_glucose_level'], y = df['stroke'],labels={
                "avg_glucose_level":"Average Glucose Level",
            }, title='Average Glucose Level Vs Occurance of Stroke')
            st.write(fig)

        #other factiors vs stroke histogram as subplots
        if col6.button("Other Factors vs Occurance of Stoke"):
            fig = make_subplots(rows=2, cols=2)
            
            #Marital Status vs stroke histogram
            fig.add_trace(
                go.Histogram(x=df['ever_married'], y=df['stroke'],name='Marital Status vs Stroke'),
                row=1, col=1
            )
        
            #Residence Type vs stroke histogram
            fig.add_trace(
                go.Histogram(x=df['Residence_type'],y=df['stroke'],name='Residence Type vs Stroke'),
                row=1, col=2
            )

            #Work Type vs stroke histogram
            fig.add_trace(
                go.Histogram(x=df['work_type'],y=df['stroke'],name='Work Type vs Stroke'),
                row=2, col=1
            )

            #Gender vs stroke histogram
            fig.add_trace(
                go.Histogram(x=df['gender'],y=df['stroke'],name='Gender vs Stroke'),
                row=2, col=2
            )
            fig.update_xaxes(title_text="Marital Status", row=1, col=1)
            fig.update_yaxes(title_text="Stroke", row=1, col=1)
            fig.update_xaxes(title_text="Residence Type", row=1, col=2)
            # fig.update_yaxes(title_text="Stroke", row=1, col=2)
            fig.update_xaxes(title_text="Work Type", row=2, col=1)
            fig.update_yaxes(title_text="Stroke", row=2, col=1)
            fig.update_xaxes(title_text="Gender", row=2, col=2)
            # fig.update_yaxes(title_text="Stroke", row=2, col=2)
            fig.update_layout(height=600, width=800, title_text="Factors vs Stroke")
            st.write(fig)

        #Encoding categorical attributes to values
        label_gender = LabelEncoder()
        label_married = LabelEncoder()
        label_work = LabelEncoder()
        label_residence = LabelEncoder()
        label_smoking = LabelEncoder()
        df['gender'] = label_gender.fit_transform(df['gender'])
        df['ever_married'] = label_married.fit_transform(df['ever_married'])
        df['work_type']= label_work.fit_transform(df['work_type'])
        df['Residence_type']= label_residence.fit_transform(df['Residence_type'])
        df['smoking_status']= label_smoking.fit_transform(df['smoking_status'])
        
        st.subheader("Data Frame after Encoding categorical attributes to values")
        st.dataframe(df)

        #Class Distribution Pie Chart
        class_occur = df['stroke'].value_counts()
        class_names = ['No Stroke','Stroke']
        fig, ax = plt.subplots(figsize=(8,4))
        ax.pie(class_occur, labels=class_names, autopct='%1.2f%%',
                shadow=True, startangle=0, counterclock=False)
        ax.axis('equal')
        ax.set_title('Class Distribution')
        st.pyplot(fig,figsize=(1, 1))
        st.write("No Stroke: {}".format(class_occur[0]))
        st.write("Stroke: {}".format(class_occur[1]))

        #Handling Imbalanced Class Data Using SMOTE Technique
        smote = SMOTE(sampling_strategy='minority')
        X, y= smote.fit_resample(df.loc[:,df.columns!='stroke'], df['stroke'])
        
        #Class Distribution Pie Chart after using SMOTE Technique
        _, class_counts = np.unique(y, return_counts=True)
        class_names = ['No stroke', 'Stroke']
        fig, ax = plt.subplots(figsize=(8,4))
        ax.pie(class_counts, labels=class_names, autopct='%1.2f%%',
                shadow=True, startangle=90, counterclock=False)
        ax.axis('equal') 
        ax.set_title('Class Distribution after performing SMOTE')
        st.write(fig)
        st.write("No Stroke: {}".format(class_counts[0]))
        st.write("Stroke: {}".format(class_counts[1]))

        #Correlation Matrix
        st.subheader("Correlation Matrix Color Map")
        fig, ax = plt.subplots(figsize=(6,4))
        im = ax.matshow(df.corr())
        ax.set_xticks(np.arange(df.shape[1]))
        ax.set_yticks(np.arange(df.shape[1]))
        ax.set_xticklabels(df.columns,rotation=90)
        ax.set_yticklabels(df.columns)

        #Creating colorbar for Correlation Matrix
        cbar = ax.figure.colorbar(im, ax=ax)
        cbar.ax.set_ylabel("Correlation", rotation=-90, va="bottom", fontsize=10)
        fig.tight_layout()
        st.write(fig)

        #Correlation Matrix HeatMap
        st.subheader("Correlation Matrix Heat Map")
        f, ax = plt.subplots(figsize = (6,4))
        corr = df.corr()
        hm = sns.heatmap(round(corr,2), annot=True, annot_kws={"size":8}, ax=ax, cmap="coolwarm",fmt='.2f',
                    linewidths=.05)
        f.subplots_adjust(top=0.93)
        t=f.suptitle("Correlation Heatmap",fontsize=10)
        st.write(f)

        #Building Data Model and Training
        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.22,random_state=42)

        #Data Standardization
        scaler = StandardScaler()
        scaler = scaler.fit(X_train)
        X_train_std = scaler.transform(X_train)
        X_test_std = scaler.transform(X_test)

        #ML Model Training and Evaluation
        model_menu = ["XGBoost (XGB) with HyperTuned Parameters","XGBoost (XGB)","Random Forest (RF)","Logistic Regression (LR)","Decision Tree (DT)","Gaussian Naive Bayes (GNB)","Singular Vector Machine (SVM)"]
        model = st.selectbox("Select a Model",model_menu)
        #XGBoost
        if model == "XGBoost (XGB)":
            start = timer.time()
            xgb_m = XGBClassifier(objective="reg:logistic", random_state=42,use_label_encoder = False)
            xgb_m.fit(X_train, y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_xgb = xgb_m.predict(X_test)
            cnf_matrix = metrics.confusion_matrix(y_test, y_xgb)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_xgb))
            st.write("Precision:",metrics.precision_score(y_test, y_xgb))
            st.write("Recall:",metrics.recall_score(y_test, y_xgb))
            st.write("F1:",metrics.f1_score(y_test, y_xgb))
        #XGBoost with HyperTuned Parameter
        elif model == "XGBoost (XGB) with HyperTuned Parameters":
            start = timer.time()
            xgb_mt = XGBClassifier(objective="reg:logistic", random_state=42,
                                use_label_encoder = False, colsample_bytree= 0.5, 
                                gamma= 0.2, learning_rate= 0.25,
                                max_depth= 10, min_child_weight= 1,)
            xgb_mt.fit(X_train, y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_xgb = xgb_mt.predict(X_test)
            y_train_predict = xgb_mt.predict(X_train)
            cnf_matrix = metrics.confusion_matrix(y_train , y_train_predict)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write('Train Accuracy',accuracy_score(y_train , y_train_predict))
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_xgb))
            st.write("Precision:",metrics.precision_score(y_test, y_xgb))
            st.write("Recall:",metrics.recall_score(y_test, y_xgb))
            st.write("F1:",metrics.f1_score(y_test, y_xgb))
        # Random Forest
        elif model == "Random Forest (RF)":
            start = timer.time()
            ranfor_m = RandomForestClassifier(n_estimators=100, random_state=42)
            ranfor_m.fit(X_train, y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_ranfor = ranfor_m.predict(X_test)
            cnf_matrix = metrics.confusion_matrix(y_test, y_ranfor)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_ranfor))
            st.write("Precision:",metrics.precision_score(y_test, y_ranfor))
            st.write("Recall:",metrics.recall_score(y_test, y_ranfor))
            st.write("F1:",metrics.f1_score(y_test, y_ranfor))
        # Decision Tree
        elif model == "Decision Tree (DT)":
            start = timer.time()
            dtree_m = DecisionTreeClassifier(random_state=42)
            dtree_m.fit(X_train, y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_dtree = dtree_m.predict(X_test)
            cnf_matrix = metrics.confusion_matrix(y_test, y_dtree)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_dtree))
            st.write("Precision:",metrics.precision_score(y_test, y_dtree))
            st.write("Recall:",metrics.recall_score(y_test, y_dtree))
            st.write("F1:",metrics.f1_score(y_test, y_dtree))
        # Logistic Regression
        elif model == "Logistic Regression (LR)":
            start = timer.time()
            logit_m = LogisticRegression(solver='lbfgs', random_state=42)
            logit_m.fit(X_train_std,y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_pred = logit_m.predict(X_test_std)
            cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_pred))
            st.write("Precision:",metrics.precision_score(y_test, y_pred))
            st.write("Recall:",metrics.recall_score(y_test, y_pred))
            st.write("F1:",metrics.f1_score(y_test, y_pred))
        # Gaussian Naive Bayes
        elif model == "Gaussian Naive Bayes (GNB)":
            start = timer.time()
            gnb_m = GaussianNB()
            gnb_m.fit(X_train, y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_gnb = gnb_m.predict(X_test)
            cnf_matrix = metrics.confusion_matrix(y_test, y_gnb)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_gnb))
            st.write("Precision:",metrics.precision_score(y_test, y_gnb))
            st.write("Recall:",metrics.recall_score(y_test, y_gnb))
            st.write("F1:",metrics.f1_score(y_test, y_gnb))
        # Singular Vector Machine
        elif model == "Singular Vector Machine (SVM)":
            start = timer.time()
            svm_m = SVC(kernel='rbf',probability=True)
            svm_m.fit(X_train_std, y_train)
            end = timer.time()
            st.success("Training time {:.2f} seconds".format(end-start))
            # Predicting test data
            y_svm = svm_m.predict(X_test_std)
            cnf_matrix = metrics.confusion_matrix(y_test, y_svm)
            st.write("Confusion matrix:\n",cnf_matrix)
            st.write("Accuracy:",metrics.accuracy_score(y_test, y_svm))
            st.write("Precision:",metrics.precision_score(y_test, y_svm))
            st.write("Recall:",metrics.recall_score(y_test, y_svm))
            st.write("F1 Score:",metrics.f1_score(y_test, y_svm))
        
        st.info("XGBoost (with Hyper Tuned Parameters) has been selected as the Best Model due to its High Accuracy compared to other models that has been Trained")

    #Prediction Page
    if activity == 'Prediction': 

        st.markdown("Enter the User's Details to predict the occurance of Stroke")
        st.text("Please Enter correct details to get better results")
        
        #Getting User Inputs
        gender = st.radio("What is User's gender",("Male","Female"))
        age = st.number_input("Enter User's age",value=40)
        hypertension = st.radio("Hypertension?",("Yes","No"))
        heart_disease = st.radio("User Ever had a heart disease?",("Yes","No"))
        ever_married = st.radio("User Ever Married?",("Yes","No"))
        work_type = st.radio("What is User's work type?",("Government Job","Private Job","Self Employed","Never Worked","Children"))
        Residence_type = st.radio("What is User's Residence type?",("Urban","Rural"))
        avg_glucose_level = st.number_input("Enter User's Average Glucose Level",value=92.35)
        
        #BMI Calculation with Height and Weight is User doesn't know BMI
        if st.checkbox("Dont Know BMI? Use height and weight"):
            height = st.number_input("Enter User's Height in cm",value=160)
            weight = st.number_input("Enter User's Weight in kgs",value=60)
            bmi = weight / (height/100)**2
            st.write("BMI of user is {:.2f} and will be autoupdated".format(bmi))
        else:
            bmi = st.number_input("Enter User's BMI",value=25.4)

        smoking_status = st.radio("User's Smoking Status?",("Unknown","Formerly Smoked","Never Smoked","Smokes"))
        
        #model (XGBoost)
        prediction_model = 'XGBoost'
        trained_model = joblib.load('Models/XGBoostTunedModel.pkl')
        model_accuracy = "94.9%"

        if st.button("Submit"):
            #Encoding categorical attributes to values
            gender = 1 if gender == 'Male' else 0
            age = float(age)
            hypertension = 1 if hypertension == 'Yes' else 0
            ever_married = 1 if ever_married == 'Yes' else 0
            heart_disease = 1 if heart_disease == 'Yes' else 0
            if work_type == 'Government Job':
                work_type = 0 
            elif work_type == 'Never Worked':
                work_type = 1 
            elif work_type == 'Private Job':
                work_type = 2 
            elif work_type == 'Self Employed':
                work_type = 3
            elif work_type == 'Children':
                work_type = 4 
            Residence_type = 1 if Residence_type == 'Urban' else 0
            avg_glucose_level = float(avg_glucose_level)
            bmi = float(bmi)
            if smoking_status == 'Unknown':
                smoking_status = 0 
            elif smoking_status == 'Formerly Smoked':
                smoking_status = 1 
            elif smoking_status == 'Never Smoked':
                smoking_status = 2
            elif smoking_status == 'Smokes':
                smoking_status = 3 

            #Creating nparray of User Inputs
            user_input = np.array([gender,age,hypertension,heart_disease,ever_married,work_type,Residence_type,avg_glucose_level,bmi,smoking_status]).reshape(1,-1)
            
            #converting into dataframe to avoid mismatching feature_names error
            user_input = pd.DataFrame(user_input, columns = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status'])
            
            #prediction using selected model
            prediction = trained_model.predict(user_input)

            #Prediction Probability
            pred_prob = trained_model.predict_proba(user_input)
            stroke_prob = pred_prob[0][1]*100

            #Printing Predicted results
            if prediction == 1:
                st.header("User has Higher Chances of having a StrokeðŸ˜”")
            else:
                st.header("User has Lower Chances of having a StrokeðŸ˜Š")
            
            #printing prediction probability 
            if stroke_prob < 25:
                st.success("Probability of Occurance of Stroke is {:.2f}%".format(stroke_prob))
            elif stroke_prob < 50:
                st.info("Probability of Occurance of Stroke is {:.2f}%".format(stroke_prob))
            elif stroke_prob < 75:
                st.warning("Probability of Occurance of Stroke is {:.2f}%".format(stroke_prob))
            else:
                st.error("Probability of Occurance of Stroke is {:.2f}%".format(stroke_prob))
            st.text("Predicted with "+prediction_model+" Model with Accuracy of " +model_accuracy)
    
if __name__ == '__main__':
    main()
